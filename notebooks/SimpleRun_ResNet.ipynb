{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ukDFxNJYYSP-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# cose"
      ],
      "metadata": {
        "id": "t1uIXyHwUk_t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RE8cOzewUfAZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow import Tensor\n",
        "from tensorflow.keras import regularizers, utils\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.initializers import he_normal, random_normal\n",
        "from tensorflow.keras.regularizers import l2, l1\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U keras-tuner\n",
        "import keras_tuner as kt"
      ],
      "metadata": {
        "id": "J1qC4SZNUqv9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b406b5-34ba-4708-e23c-69e22c1b03a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 KB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "raw_data_pd = pd.read_pickle(r'drive/MyDrive/AML_2022-2023/data_raw.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xVX4ajBUuY0",
        "outputId": "78909cca-674c-467e-a8fa-f7dd4b0b7ba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_by_index(data_obj, idx, draw_legend=True):\n",
        "  plt.plot(data_obj['x-axis'][idx], data_obj['spectra'][idx], label=f'{data_obj[\"user\"][idx]} ({idx})')\n",
        "  if draw_legend:\n",
        "    plt.legend()\n",
        "\n",
        "def draw_by_user(data_obj, user):\n",
        "  for i, x in enumerate(data_obj['user']):\n",
        "    if x == user:\n",
        "      plt.plot(data_obj['x-axis'][i], data_obj['spectra'][i])\n",
        "\n",
        "def draw_by_category(data_obj, category):\n",
        "  for i, x in enumerate(data_obj['category']):\n",
        "    if x == category:\n",
        "      plt.plot(data_obj['x-axis'][i], data_obj['spectra'][i])\n",
        "\n",
        "def is_outlier(data_obj, idx, treshold=1200, val_out=64500):\n",
        "  spectra = data_obj['spectra'][idx]\n",
        "  x = data_obj['x-axis'][idx]\n",
        "  ma_arr = np.ma.masked_less(x, treshold)\n",
        "  masked = np.ma.masked_where(np.ma.getmask(ma_arr), spectra)\n",
        "  return masked.max() == val_out\n",
        "\n",
        "def how_many_outliers(data_obj, treshold=1200, val_out=64500):\n",
        "  count = 0\n",
        "  for idx, _ in enumerate(data_obj['user']):\n",
        "    if is_outlier(data_obj, idx, treshold, val_out):\n",
        "      count += 1\n",
        "  return count\n",
        "\n",
        "def get_dataset_no_outliers(data_obj, treshold=1200, val_out=64500):\n",
        "  new_df = data_obj.copy()\n",
        "  idexes_outliers = []\n",
        "  for idx, _ in enumerate(data_obj['user']):\n",
        "    if is_outlier(data_obj, idx, treshold, val_out):\n",
        "      idexes_outliers.append(idx)\n",
        "  return new_df.drop(idexes_outliers).reset_index()\n",
        "\n",
        "def get_dataset_fitted(data_obj, deg=4, val_out=64500):\n",
        "  new_df = data_obj.copy()\n",
        "  for idx, _ in enumerate(new_df['user']):\n",
        "    y = get_fitted(new_df, idx, deg, val_out)\n",
        "    #new_df.loc[idx, 'spectra'] = new_df['spectra'][idx] - y\n",
        "    new_df['spectra'][idx] = new_df['spectra'][idx] - y\n",
        "  return new_df\n",
        "\n",
        "def get_fitted(data_obj, idx, deg=5, val_out=64500):\n",
        "  y = data_obj['spectra'][idx]\n",
        "  my = np.ma.masked_equal(y, val_out)\n",
        "  x = data_obj['x-axis'][idx]\n",
        "  mx = np.ma.masked_where(np.ma.getmask(my), x)\n",
        "  poly = np.polyfit(mx, my, deg=deg)\n",
        "  return np.polyval(poly, mx).filled(val_out)\n",
        "\n",
        "def draw_by_index_fitted(data_obj, idx, deg=5, draw_legend=True):\n",
        "  x = data_obj['x-axis'][idx]\n",
        "  y = data_obj['spectra'][idx]\n",
        "  fit = get_fitted(data_obj, idx, deg)\n",
        "  plt.plot(x, y-fit, label=f'{data_obj[\"user\"][idx]} ({idx})')\n",
        "  if draw_legend:\n",
        "    plt.legend()\n",
        "\n",
        "def draw_by_user_fitted(data_obj, user, deg=5):\n",
        "  for i, x in enumerate(data_obj['user']):\n",
        "    if x == user:\n",
        "      draw_by_index_fitted(data_obj, i, deg, False)\n",
        "\n",
        "def draw_by_category_fitted(data_obj, category, deg=5):\n",
        "  for i, x in enumerate(data_obj['category']):\n",
        "    if x == category:\n",
        "      draw_by_index_fitted(data_obj, i, deg, False)\n",
        "\n",
        "def plot_history(history, validation=True):\n",
        "  \n",
        "  fig, axs = plt.subplots(1, 2, figsize=(20,5))\n",
        "\n",
        "  axs[0].plot(history.history['loss'])\n",
        "  if validation:\n",
        "    axs[0].plot(history.history['val_loss'])\n",
        "    #overfitepoch = np.where(np.array(history.history['val_loss']) == min(history.history['val_loss']))\n",
        "    #axs[0].vlines(overfitepoch, 0, 1.5) \n",
        "  axs[0].set_title('Loss')\n",
        "  axs[0].set_ylabel('Loss')\n",
        "  axs[0].set_xlabel('Epoch')\n",
        "  axs[0].grid()\n",
        "\n",
        "  axs[1].plot(history.history['categorical_accuracy'])\n",
        "  if validation:\n",
        "    axs[1].plot(history.history['val_categorical_accuracy'])\n",
        "    #axs[1].vlines(overfitepoch, 0.6, 1)  \n",
        "  axs[1].set_title('Categorical accuracy')\n",
        "  axs[1].set_ylabel('Categorical accuracy')\n",
        "  axs[1].set_xlabel('Epoch')\n",
        "  axs[1].grid()\n",
        "\n",
        "  if validation:\n",
        "    plt.figlegend(['Train set', 'Validation set'], loc='upper center',\n",
        "                  fontsize=14, ncol=2)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  # Print final values\n",
        "  print('At the',len(history.history['loss']), 'th epoch: \\n')\n",
        "  print('The loss:', history.history['loss'][-1])\n",
        "  print('The categorical_accuracy', history.history['categorical_accuracy'][-1])\n",
        "  if validation:\n",
        "    print('The val_loss:', history.history['val_loss'][-1])\n",
        "    print('The val_categorical_accuracy:', history.history['val_categorical_accuracy'][-1])\n",
        "\n",
        "\n",
        "def plot_history_bin(history, validation=True):\n",
        "  \n",
        "  fig, axs = plt.subplots(1, 2, figsize=(20,5))\n",
        "\n",
        "  axs[0].plot(history.history['loss'])\n",
        "  if validation:\n",
        "    axs[0].plot(history.history['val_loss'])\n",
        "    #overfitepoch = np.where(np.array(history.history['val_loss']) == min(history.history['val_loss']))\n",
        "    #axs[0].vlines(overfitepoch, 0, 1.5) \n",
        "  axs[0].set_title('Loss')\n",
        "  axs[0].set_ylabel('Loss')\n",
        "  axs[0].set_xlabel('Epoch')\n",
        "  axs[0].grid()\n",
        "\n",
        "  axs[1].plot(history.history['accuracy'])\n",
        "  if validation:\n",
        "    axs[1].plot(history.history['val_accuracy'])\n",
        "    #axs[1].vlines(overfitepoch, 0.6, 1)  \n",
        "  axs[1].set_title('Accuracy')\n",
        "  axs[1].set_ylabel('Accuracy')\n",
        "  axs[1].set_xlabel('Epoch')\n",
        "  axs[1].grid()\n",
        "\n",
        "  if validation:\n",
        "    plt.figlegend(['Train set', 'Validation set'], loc='upper center',\n",
        "                  fontsize=14, ncol=2)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  # Print final values\n",
        "  print('At the',len(history.history['loss']), 'th epoch: \\n')\n",
        "  print('The loss:', history.history['loss'][-1])\n",
        "  print('The accuracy', history.history['accuracy'][-1])\n",
        "  if validation:\n",
        "    print('The val_loss:', history.history['val_loss'][-1])\n",
        "    print('The val_accuracy:', history.history['val_accuracy'][-1])"
      ],
      "metadata": {
        "id": "Af1jjEBUU-g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_preprocessed_data_1d(raw_dataset, train_pr=0.5, val_pr=0.25, test_pr=0.25, augment=False):\n",
        "  clean_dataset = get_dataset_no_outliers(raw_dataset, treshold=400)\n",
        "\n",
        "  x_train, y_train, x_val, y_val, x_test, y_test = dataset_split(clean_dataset, \n",
        "                                                                 train_pr=train_pr,\n",
        "                                                                 val_pr=val_pr,\n",
        "                                                                 test_pr=test_pr)\n",
        "  x_train = normalize(x_train)\n",
        "  x_val = normalize(x_val)\n",
        "  x_test_norm = normalize(x_test)\n",
        "\n",
        "  divided_spectra = divide_spectra(x_test, x_test_norm, raw_dataset)\n",
        "\n",
        "  if augment:\n",
        "    x_train, y_train = data_augmentation(x_train, y_train)\n",
        "  \n",
        "  return x_train, y_train, x_val, y_val, x_test, y_test, x_test_norm, divided_spectra"
      ],
      "metadata": {
        "id": "FkkUz3hhVXxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user(spectra, data, tupled):\n",
        "  idx = raw_data_pd.index[tupled == tuple(spectra)][0]\n",
        "  return data['user'][idx]\n",
        "\n",
        "def divide_spectra(x_test, x_test_norm, data):\n",
        "  results = {}\n",
        "  patients = data['user'].unique()\n",
        "  tupled = raw_data_pd.spectra.map(tuple)\n",
        "  for p in patients:\n",
        "    results[p] = []\n",
        "\n",
        "  for idx, spectra in enumerate(x_test):\n",
        "    user = get_user(spectra, data, tupled)\n",
        "    results[user].append(x_test_norm[idx])\n",
        "\n",
        "  return {k:v for k,v in results.items() if v}"
      ],
      "metadata": {
        "id": "4_HZ6A3IVugk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label(patients):\n",
        "  \n",
        "  label=[]\n",
        "  for p in patients:\n",
        "    if 'COV+' in p:\n",
        "      label.append(0)\n",
        "    \n",
        "    elif 'COV-' in p:\n",
        "      label.append(1)\n",
        "    \n",
        "    elif 'CTRL' in p:\n",
        "      label.append(2)\n",
        "\n",
        "  return label"
      ],
      "metadata": {
        "id": "y3wOnHxlVwEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_split(data, train_pr, val_pr, test_pr):\n",
        "\n",
        "  patients = data['user'].unique()\n",
        "  val_pr=val_pr*(1+test_pr)\n",
        "  # x1: train, x2: val, x3: test\n",
        "  x1, x3 = train_test_split(patients, test_size=test_pr, stratify=get_label(patients))\n",
        "  x1, x2= train_test_split(x1, test_size=val_pr, stratify=get_label(x1))\n",
        "\n",
        "  x_train=[]\n",
        "  x_val=[]\n",
        "  x_test=[]\n",
        "\n",
        "  train_users = []\n",
        "  test_users = []\n",
        "  val_users = []\n",
        "\n",
        "  for idx, user in enumerate(raw_data_pd['user']):\n",
        "    if user in x1:\n",
        "      x_train.append(raw_data_pd['spectra'][idx])\n",
        "      train_users.append(raw_data_pd['user'][idx])\n",
        "    elif user in x2:\n",
        "      x_val.append(raw_data_pd['spectra'][idx])\n",
        "      val_users.append(raw_data_pd['user'][idx])\n",
        "    elif user in x3:\n",
        "      x_test.append(raw_data_pd['spectra'][idx])\n",
        "      test_users.append(raw_data_pd['user'][idx])\n",
        "\n",
        "  y_train=get_label(train_users)\n",
        "  y_val=get_label(val_users)\n",
        "  y_test=get_label(test_users)\n",
        "\n",
        "  y_train = utils.to_categorical(y_train, 3)\n",
        "  y_test = utils.to_categorical(y_test, 3)\n",
        "  y_val = utils.to_categorical(y_val, 3)\n",
        "\n",
        "  x_train = np.array(x_train)\n",
        "  x_val = np.array(x_val)\n",
        "  x_test = np.array(x_test)\n",
        "\n",
        "  return x_train, y_train, x_val, y_val, x_test, y_test"
      ],
      "metadata": {
        "id": "v4iRfiJ5Vxqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(x):\n",
        "\n",
        "  new_x=[]\n",
        "\n",
        "  for spectra in x:\n",
        "    #new_x.append(spectra/max(spectra))\n",
        "    new_x.append(spectra/spectra[0])\n",
        "    #new_x.append(spectra/np.mean(spectra))\n",
        "    \n",
        "  return np.array(new_x)\n",
        "#gaussian noise\n",
        "\n",
        "def data_augmentation(x, y, n_spectra=5):\n",
        "  new_x = []\n",
        "  new_y = []\n",
        "\n",
        "  for idx, s in enumerate(x):\n",
        "    for n in range(n_spectra):\n",
        "      noise = np.random.normal(0,0.0005,991)\n",
        "      new_spectra = s+noise\n",
        "      new_x.append(new_spectra)\n",
        "      new_y.append(y[idx])\n",
        "\n",
        "  return np.array(new_x), np.array(new_y)"
      ],
      "metadata": {
        "id": "1UxjTuVyVzVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def patients_results(model, spectra_patients, majority=False):\n",
        "  results = {\n",
        "    \"user\": [],\n",
        "    \"prob_cov+\": [],\n",
        "    \"prob_cov-\": [],\n",
        "    \"prob_ctrl\": [],\n",
        "    \"prediction\": [],\n",
        "    \"correct_value\": []\n",
        "  }\n",
        "  for patient in spectra_patients.keys():\n",
        "    r = model.predict(np.array(spectra_patients[patient]), verbose=0)\n",
        "    \n",
        "    if majority:\n",
        "      r = np.argmax(r, axis=1)\n",
        "      count=[]\n",
        "\n",
        "      for i in range(3):\n",
        "        count.append((r==i).sum())\n",
        "\n",
        "      pred = np.argmax(count)\n",
        "    \n",
        "    else:\n",
        "      r = r.sum(axis=0)\n",
        "      r = r / len(spectra_patients[patient])\n",
        "      pred = r.argmax()\n",
        "        \n",
        "    \n",
        "    if pred == 0:\n",
        "      pred = 'COV+'\n",
        "    elif pred == 1:\n",
        "      pred = 'COV-'\n",
        "    elif pred == 2:\n",
        "      pred = 'CTRL'\n",
        "\n",
        "    if 'COV+' in patient:\n",
        "      cor = 'COV+'\n",
        "    elif 'COV-' in patient:\n",
        "      cor = 'COV-'\n",
        "    elif 'CTRL' in patient:\n",
        "      cor = 'CTRL'\n",
        "\n",
        "    results[\"user\"].append(patient)\n",
        "    results[\"prob_cov+\"].append(r[0])\n",
        "    results[\"prob_cov-\"].append(r[1])\n",
        "    results[\"prob_ctrl\"].append(r[2])\n",
        "    results[\"prediction\"].append(pred)\n",
        "    results[\"correct_value\"].append(cor)\n",
        "\n",
        "  return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "kE9-_lhXV2vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def patients_accuracy_tern(results):\n",
        "\n",
        "  correct = 0\n",
        "\n",
        "  for idx, _ in enumerate(results['user']):\n",
        "    if results['prediction'][idx] == results['correct_value'][idx]:\n",
        "      correct += 1\n",
        "\n",
        "  return correct/len(results)\n",
        "\n",
        "def patients_accuracy(results):\n",
        "  \n",
        "  correct = 0\n",
        "\n",
        "  for idx, _ in enumerate(results['user']):\n",
        "\n",
        "    if results['prediction'][idx]=='COV+':\n",
        "      if results['correct_value'][idx]=='COV+':\n",
        "        correct += 1\n",
        "    else:\n",
        "      if results['correct_value'][idx] != 'COV+':\n",
        "        correct+=1\n",
        "\n",
        "  return correct/len(results)\n",
        "\n",
        "def patients_sensitivity(results):\n",
        "\n",
        "  true_positive = 0\n",
        "  false_negative = 0\n",
        "\n",
        "  for idx, _ in enumerate(results['user']):\n",
        "    pred = results['prediction'][idx]\n",
        "    res = results['correct_value'][idx]\n",
        "    if pred == 'COV+' and res == 'COV+':\n",
        "      true_positive += 1\n",
        "    elif pred != 'COV+' and res == 'COV+':\n",
        "      false_negative += 1\n",
        "\n",
        "  try:\n",
        "    return true_positive/(true_positive+false_negative)\n",
        "  except:\n",
        "    return float('NaN')\n",
        "\n",
        "def patients_specifity(results):\n",
        "\n",
        "  true_negative = 0\n",
        "  false_positive = 0\n",
        "\n",
        "  for idx, _ in enumerate(results['user']):\n",
        "    pred = results['prediction'][idx]\n",
        "    res = results['correct_value'][idx]\n",
        "    if pred != 'COV+' and res != 'COV+':\n",
        "      true_negative += 1\n",
        "    elif pred == 'COV+' and res != 'COV+':\n",
        "      false_positive += 1\n",
        "\n",
        "  try:\n",
        "    return true_negative/(true_negative+false_positive)\n",
        "  except:\n",
        "    return float('NaN')"
      ],
      "metadata": {
        "id": "C1X0ZehIV5ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def patients_confusion_matrix(results):\n",
        "\n",
        "  y_pred = results['prediction']\n",
        "  y_true = results['correct_value']\n",
        "\n",
        "  label=['COV+', 'COV-', 'CTRL']\n",
        "\n",
        "  mat=ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred), display_labels=label)\n",
        "  mat.plot()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "tv9KAUicV8RV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def divide_patients_in_category(patients):\n",
        "  cov_p = []\n",
        "  cov_m = []\n",
        "  ctrl = []\n",
        "\n",
        "  for p in patients:\n",
        "    if 'COV+' in p:\n",
        "      cov_p.append(p)\n",
        "    elif 'COV-' in p:\n",
        "      cov_m.append(p)\n",
        "    elif 'CTRL' in p:\n",
        "      ctrl.append(p)\n",
        "  return cov_p, cov_m, ctrl"
      ],
      "metadata": {
        "id": "JWvS0bkXV-gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def divide_patients_in_groups(patients, k=1):\n",
        "  \n",
        "  cov_p, cov_m, ctrl = divide_patients_in_category(patients)\n",
        "\n",
        "\n",
        "  random.shuffle(cov_p)\n",
        "  random.shuffle(cov_m)\n",
        "  random.shuffle(ctrl)\n",
        "  \n",
        "  total_num = len(cov_p) \n",
        "\n",
        "  new_k = int(np.floor(k / 3))\n",
        "\n",
        "  new_division = []\n",
        "\n",
        "  for i in np.arange(0,total_num, new_k, dtype='int32'):\n",
        "    temp_y = []\n",
        "    temp_y.append(cov_p[i:i+new_k])\n",
        "    temp_y.append(cov_m[i:i+new_k])\n",
        "    temp_y.append(ctrl[i:i+new_k])\n",
        "\n",
        "    new_division.append(np.reshape(temp_y, (len(temp_y)*new_k, ) ))\n",
        "  return new_division"
      ],
      "metadata": {
        "id": "NySNDcULWAf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_split_by_names(odataset, test_names):\n",
        "\n",
        "  dataset = odataset.copy()\n",
        "  x_test = []\n",
        "  y_test = []\n",
        "\n",
        "  x_train = []\n",
        "  y_train = []\n",
        "\n",
        "  for idx, name in enumerate(dataset['user']):\n",
        "    if name in test_names:\n",
        "      x_test.append(dataset['spectra'][idx])\n",
        "      y_test.append(name)\n",
        "    else:\n",
        "      x_train.append(dataset['spectra'][idx])\n",
        "      y_train.append(name)\n",
        "\n",
        "  y_train=get_label(y_train)\n",
        "  y_test=get_label(y_test)\n",
        "\n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "metadata": {
        "id": "finJ-EB8WCcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_lopocv(raw_dataset, make_model, augment=False, k=1):\n",
        "  dataset = get_dataset_no_outliers(raw_dataset, treshold=400)\n",
        "\n",
        "  patients = dataset.user.unique()\n",
        "  division = divide_patients_in_groups(patients, k)\n",
        "\n",
        "  accuracies_tern = []\n",
        "  accuracies = []\n",
        "  sensitivity = []\n",
        "  specificity = []\n",
        "\n",
        "  maj_accuracies_tern = []\n",
        "  maj_accuracies = []\n",
        "  maj_sensitivity = []\n",
        "  maj_specificity = []\n",
        "\n",
        "  for idx, testset in enumerate(division):\n",
        "    x_train, y_train, x_test, y_test = get_split_by_names(dataset, testset)\n",
        "\n",
        "    x_train = normalize(np.array(x_train))\n",
        "    x_test_norm = normalize(np.array(x_test))\n",
        "\n",
        "    divided_spectra = divide_spectra(x_test, x_test_norm, raw_dataset)\n",
        "\n",
        "    if augment:\n",
        "      x_train, y_train = data_augmentation(x_train, y_train)\n",
        "  \n",
        "    y_train = utils.to_categorical(y_train, 3)\n",
        "    y_test = utils.to_categorical(y_test, 3)\n",
        "\n",
        "    x_train = np.array(x_train)\n",
        "    x_test = np.array(x_test)\n",
        "\n",
        "\n",
        "    batch_size = 32\n",
        "    n_epochs = 15\n",
        "    \n",
        "    checkpoint_path = '/tmp/checkpoint' \n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "      filepath=checkpoint_path,\n",
        "      save_weights_only=True,\n",
        "      monitor='categorical_accuracy',\n",
        "      mode='max',\n",
        "      save_best_only=True)\n",
        "  \n",
        "    model_earlystopping_callback = EarlyStopping(\n",
        "      monitor='categorical_accuracy',\n",
        "      min_delta=0.01,\n",
        "      patience=50,\n",
        "      verbose=1\n",
        "    )\n",
        "\n",
        "    clear_session()\n",
        "    model = make_model()\n",
        "    network_history = model.fit(x_train, y_train, batch_size=batch_size, \n",
        "                                callbacks=[model_checkpoint_callback,\n",
        "                                           model_earlystopping_callback],\n",
        "                                epochs=n_epochs, verbose=0,\n",
        "                                validation_data=(x_test_norm, y_test))\n",
        "    model.load_weights(checkpoint_path)\n",
        "    #plot_history(network_history, False)\n",
        "  \n",
        "    df_res = patients_results(model, divided_spectra, majority=False)\n",
        "    accuracies_tern.append(patients_accuracy_tern(df_res))\n",
        "    accuracies.append(patients_accuracy(df_res))\n",
        "    sensitivity.append(patients_sensitivity(df_res))\n",
        "    specificity.append(patients_specifity(df_res))\n",
        "\n",
        "    maj_df_res = patients_results(model, divided_spectra, majority=True)\n",
        "    maj_accuracies_tern.append(patients_accuracy_tern(maj_df_res))\n",
        "    maj_accuracies.append(patients_accuracy(maj_df_res))\n",
        "    maj_sensitivity.append(patients_sensitivity(maj_df_res))\n",
        "    maj_specificity.append(patients_specifity(maj_df_res))\n",
        "\n",
        "\n",
        "\n",
        "    print(f'\\nIterazione {idx}')\n",
        "    print(f'\\tTrainAcc={network_history.history[\"categorical_accuracy\"][-1]}')\n",
        "\n",
        "    print(f'\\nMajority=False')\n",
        "    print(f'\\tTernAcc={accuracies_tern[-1]}')\n",
        "    print(f'\\tBinAcc={accuracies[-1]}')\n",
        "    print(f'\\tSens={sensitivity[-1]}')\n",
        "    print(f'\\tSpec={specificity[-1]}')\n",
        "\n",
        "    print(f'\\nMajority=Turne')\n",
        "    print(f'\\tTernAcc={maj_accuracies_tern[-1]}')\n",
        "    print(f'\\tBinAcc={maj_accuracies[-1]}')\n",
        "    print(f'\\tSens={maj_sensitivity[-1]}')\n",
        "    print(f'\\tSpec={maj_specificity[-1]}')\n",
        "    #print(df_res)\n",
        "\n",
        "  return accuracies_tern, accuracies, sensitivity, specificity, maj_accuracies_tern, maj_accuracies, maj_sensitivity, maj_specificity"
      ],
      "metadata": {
        "id": "LaFdLCdoWEqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperband"
      ],
      "metadata": {
        "id": "ukDFxNJYYSP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu_bn(inputs):\n",
        "    relu = ReLU()(inputs)\n",
        "    bn = BatchNormalization()(relu)\n",
        "    return bn\n",
        "\n",
        "def residual_block(x, downsample, filters, kernel_size = 3):\n",
        "    y = Conv1D(kernel_size=kernel_size,\n",
        "               strides= (1 if not downsample else 2),\n",
        "               filters=filters,\n",
        "               padding=\"same\")(x)\n",
        "    y = relu_bn(y)\n",
        "    y = Conv1D(kernel_size=kernel_size,\n",
        "               strides=1,\n",
        "               filters=filters,\n",
        "               padding=\"same\")(y)\n",
        "\n",
        "    if downsample:\n",
        "        x = Conv1D(kernel_size=1,\n",
        "                   strides=2,\n",
        "                   filters=filters,\n",
        "                   padding=\"same\")(x)\n",
        "\n",
        "    out = Add()([x, y])\n",
        "    out = relu_bn(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "9z5Bo8rGYStr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_res_net1D_hp(hp):\n",
        "\n",
        "  num_filters = 64 #hp.Int('num_filters', min_value=12, max_value=64, step=12)\n",
        "\n",
        "  num1 = hp.Int('num1', min_value=1, max_value=5, step=1)\n",
        "  num2 = hp.Int('num2', min_value=1, max_value=5, step=1)\n",
        "  #num3 = hp.Int('num3', min_value=1, max_value=5, step=1)\n",
        "  #num4 = hp.Int('num4', min_value=1, max_value=5, step=1)\n",
        "\n",
        "  gaus = hp.Float('gaus', min_value=0., max_value=0.1, step=0.005)\n",
        "  kern_size = hp.Int('kern_size', min_value=5, max_value=11, step=1)\n",
        "\n",
        "  num_blocks_list = [num1, num2] #, num3, num4]\n",
        "\n",
        "  \n",
        "  inputs = Input(shape=(991, 1))\n",
        "\n",
        "  gaussian = GaussianNoise(gaus)(inputs)\n",
        "  \n",
        "  t = BatchNormalization()(gaussian)\n",
        "  t = Conv1D(kernel_size=kern_size,\n",
        "              strides=1,\n",
        "              filters=num_filters,\n",
        "              padding=\"same\")(t)\n",
        "  t = relu_bn(t)\n",
        "  \n",
        "  t = MaxPool1D(2)(t)\n",
        "  \n",
        "  \n",
        "  for i in range(len(num_blocks_list)):\n",
        "      num_blocks = num_blocks_list[i]\n",
        "      for j in range(num_blocks):\n",
        "          t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
        "      num_filters *= 2\n",
        "  \n",
        "  t = AveragePooling1D(4)(t)\n",
        "  t = Flatten()(t)\n",
        "  outputs = Dense(3, activation='softmax')(t)\n",
        "  \n",
        "  model = Model(inputs, outputs)\n",
        "\n",
        "  model.compile(\n",
        "      optimizer='adam',\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['categorical_accuracy']\n",
        "  )\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Q_fW75tBZzGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(create_res_net1D_hp,\n",
        "                     objective='val_categorical_accuracy',\n",
        "                     max_epochs=1,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='prova4')\n",
        "\n",
        "x_train, y_train, x_val, y_val, x_test, y_test, x_test_norm, divided_spectra = get_preprocessed_data_1d(raw_data_pd,\n",
        "                                                                                                        augment=False)\n",
        "\n",
        "tuner.search(x_train, y_train, epochs=1, validation_data=(x_val, y_val))\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(best_hps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1myhVEMAZ1tP",
        "outputId": "764dd5b5-19a2-43b5-91f7-e95c1a71e296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 Complete [00h 00m 27s]\n",
            "val_categorical_accuracy: 0.2916666567325592\n",
            "\n",
            "Best val_categorical_accuracy So Far: 0.2916666567325592\n",
            "Total elapsed time: 00h 00m 27s\n",
            "<keras_tuner.engine.hyperparameters.HyperParameters object at 0x7f26f0132f70>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_hps.get('num_filters'))\n",
        "print(best_hps.get('num1'))\n",
        "print(best_hps.get('num2'))\n",
        "print(best_hps.get('num3'))\n",
        "print(best_hps.get('num4'))\n",
        "print(best_hps.get('gaus'))\n",
        "print(best_hps.get('kern_size'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "XsrB0lMBahcr",
        "outputId": "8f169ae7-c9e1-4206-b1b4-28959365436d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-f6f26eb22c6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_hps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num_filters'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_hps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_hps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_hps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_hps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/hyperparameters.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} is currently inactive.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} does not exist.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'num_filters does not exist.'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "vS_ixOm9UyWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model():\n",
        "\n",
        "\n",
        "  num1 = 5 # best_hps.get('num1')\n",
        "  num2 = 4 # best_hps.get('num2')\n",
        "  gaus = 0.01 # best_hps.get('gaus')\n",
        "  kern_size = 10 # best_hps.get('kern_size')\n",
        "\n",
        "\n",
        "  num_filters = 64 \n",
        "  num_blocks_list = [num1, num2] \n",
        "\n",
        "  \n",
        "  inputs = Input(shape=(991, 1))\n",
        "\n",
        "  gaussian = GaussianNoise(gaus)(inputs)\n",
        "  \n",
        "  t = BatchNormalization()(gaussian)\n",
        "  t = Conv1D(kernel_size=kern_size,\n",
        "              strides=1,\n",
        "              filters=num_filters,\n",
        "              padding=\"same\")(t)\n",
        "  t = relu_bn(t)\n",
        "  \n",
        "  t = MaxPool1D(2)(t)\n",
        "  \n",
        "  \n",
        "  for i in range(len(num_blocks_list)):\n",
        "      num_blocks = num_blocks_list[i]\n",
        "      for j in range(num_blocks):\n",
        "          t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
        "      num_filters *= 2\n",
        "  \n",
        "  t = AveragePooling1D(4)(t)\n",
        "  t = Flatten()(t)\n",
        "  outputs = Dense(3, activation='softmax')(t)\n",
        "  \n",
        "  model = Model(inputs, outputs)\n",
        "\n",
        "  model.compile(\n",
        "      optimizer='adam',\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['categorical_accuracy']\n",
        "  )\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "9rGi3xGPYiAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9VRfeWU-iKh",
        "outputId": "e15d98fd-a819-414c-a95e-7dae30d2c9c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 991, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " gaussian_noise_1 (GaussianNois  (None, 991, 1)      0           ['input_2[0][0]']                \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 991, 1)      4           ['gaussian_noise_1[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 991, 64)      704         ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                   (None, 991, 64)      0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 991, 64)     256         ['re_lu[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 495, 64)      0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 495, 64)      12352       ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)                 (None, 495, 64)      0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 495, 64)     256         ['re_lu_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 495, 64)      12352       ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 495, 64)      0           ['max_pooling1d[0][0]',          \n",
            "                                                                  'conv1d_3[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)                 (None, 495, 64)      0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 495, 64)     256         ['re_lu_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 495, 64)      12352       ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)                 (None, 495, 64)      0           ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 495, 64)     256         ['re_lu_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 495, 64)      12352       ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 495, 64)      0           ['batch_normalization_4[0][0]',  \n",
            "                                                                  'conv1d_5[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)                 (None, 495, 64)      0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 495, 64)     256         ['re_lu_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 495, 64)      12352       ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)                 (None, 495, 64)      0           ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 495, 64)     256         ['re_lu_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 495, 64)      12352       ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 495, 64)      0           ['batch_normalization_6[0][0]',  \n",
            "                                                                  'conv1d_7[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)                 (None, 495, 64)      0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 495, 64)     256         ['re_lu_6[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 495, 64)      12352       ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)                 (None, 495, 64)      0           ['conv1d_8[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 495, 64)     256         ['re_lu_7[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 495, 64)      12352       ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 495, 64)      0           ['batch_normalization_8[0][0]',  \n",
            "                                                                  'conv1d_9[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)                 (None, 495, 64)      0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 495, 64)     256         ['re_lu_8[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 495, 64)      12352       ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)                 (None, 495, 64)      0           ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 495, 64)     256         ['re_lu_9[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 495, 64)      12352       ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 495, 64)      0           ['batch_normalization_10[0][0]', \n",
            "                                                                  'conv1d_11[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)                (None, 495, 64)      0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 495, 64)     256         ['re_lu_10[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 248, 128)     24704       ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)                (None, 248, 128)     0           ['conv1d_12[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 248, 128)    512         ['re_lu_11[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 248, 128)     8320        ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 248, 128)     49280       ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 248, 128)     0           ['conv1d_14[0][0]',              \n",
            "                                                                  'conv1d_13[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)                (None, 248, 128)     0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 248, 128)    512         ['re_lu_12[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)             (None, 248, 128)     49280       ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)                (None, 248, 128)     0           ['conv1d_15[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 248, 128)    512         ['re_lu_13[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)             (None, 248, 128)     49280       ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 248, 128)     0           ['batch_normalization_14[0][0]', \n",
            "                                                                  'conv1d_16[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)                (None, 248, 128)     0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 248, 128)    512         ['re_lu_14[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)             (None, 248, 128)     49280       ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)                (None, 248, 128)     0           ['conv1d_17[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 248, 128)    512         ['re_lu_15[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_18 (Conv1D)             (None, 248, 128)     49280       ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 248, 128)     0           ['batch_normalization_16[0][0]', \n",
            "                                                                  'conv1d_18[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_16 (ReLU)                (None, 248, 128)     0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 248, 128)    512         ['re_lu_16[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_19 (Conv1D)             (None, 248, 128)     49280       ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_17 (ReLU)                (None, 248, 128)     0           ['conv1d_19[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 248, 128)    512         ['re_lu_17[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_20 (Conv1D)             (None, 248, 128)     49280       ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 248, 128)     0           ['batch_normalization_18[0][0]', \n",
            "                                                                  'conv1d_20[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_18 (ReLU)                (None, 248, 128)     0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 248, 128)    512         ['re_lu_18[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " average_pooling1d (AveragePool  (None, 62, 128)     0           ['batch_normalization_20[0][0]'] \n",
            " ing1D)                                                                                           \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 7936)         0           ['average_pooling1d[0][0]']      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 3)            23811       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 532,935\n",
            "Trainable params: 529,477\n",
            "Non-trainable params: 3,458\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_tern, acc, sens, spec, m_acc_tern, m_acc, m_sens, m_spec = train_lopocv(raw_data_pd, make_model,\n",
        "                                                                            k=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EjBOOZSWUKb",
        "outputId": "2d1d69d3-1a53-48c0-9459-912db6e6feb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iterazione 0\n",
            "\tTrainAcc=0.8129310607910156\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=1.0\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=1.0\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 1\n",
            "\tTrainAcc=0.8081069588661194\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=1.0\n",
            "\tSpec=0.5\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.3333333333333333\n",
            "\tBinAcc=0.3333333333333333\n",
            "\tSens=1.0\n",
            "\tSpec=0.0\n",
            "\n",
            "Iterazione 2\n",
            "\tTrainAcc=0.8182209134101868\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=1.0\n",
            "\tSpec=0.5\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=1.0\n",
            "\tSpec=0.5\n",
            "\n",
            "Iterazione 3\n",
            "\tTrainAcc=0.8119621276855469\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=0.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=1.0\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 4\n",
            "\tTrainAcc=0.8112068772315979\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 5\n",
            "\tTrainAcc=0.8047311902046204\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=1.0\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=1.0\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 6\n",
            "\tTrainAcc=0.795376718044281\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=1.0\n",
            "\tSpec=0.5\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=1.0\n",
            "\tSpec=0.5\n",
            "\n",
            "Iterazione 7\n",
            "\tTrainAcc=0.8059508204460144\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=1.0\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=1.0\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 8\n",
            "\tTrainAcc=0.8185726404190063\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=0.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=0.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 9\n",
            "\tTrainAcc=0.8175938129425049\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=1.0\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=1.0\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 10\n",
            "\tTrainAcc=0.8214592337608337\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.3333333333333333\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=0.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.3333333333333333\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=0.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 11\n",
            "\tTrainAcc=0.8098106980323792\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 12\n",
            "\tTrainAcc=0.8234536051750183\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.3333333333333333\n",
            "\tBinAcc=0.3333333333333333\n",
            "\tSens=0.0\n",
            "\tSpec=0.5\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.3333333333333333\n",
            "\tBinAcc=0.3333333333333333\n",
            "\tSens=0.0\n",
            "\tSpec=0.5\n",
            "\n",
            "Iterazione 13\n",
            "\tTrainAcc=0.8017241358757019\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=0.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=0.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 14\n",
            "\tTrainAcc=0.8171256184577942\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=0.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=0.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 15\n",
            "\tTrainAcc=0.8089693784713745\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=0.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=0.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 16\n",
            "\tTrainAcc=0.812875509262085\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=1.0\n",
            "\tSpec=0.5\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=1.0\n",
            "\tSpec=0.5\n",
            "\n",
            "Iterazione 17\n",
            "\tTrainAcc=0.80378657579422\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=1.0\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 18\n",
            "\tTrainAcc=0.8106942772865295\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.3333333333333333\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=0.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.3333333333333333\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=0.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 19\n",
            "\tTrainAcc=0.8070628643035889\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=1.0\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=1.0\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 20\n",
            "\tTrainAcc=0.7874083518981934\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=1.0\n",
            "\tSpec=0.5\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=1.0\n",
            "\tSpec=0.5\n",
            "\n",
            "Iterazione 21\n",
            "\tTrainAcc=0.8081069588661194\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 22\n",
            "\tTrainAcc=0.8119879364967346\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=1.0\n",
            "\tSpec=0.5\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=1.0\n",
            "\tSpec=0.5\n",
            "\n",
            "Iterazione 23\n",
            "\tTrainAcc=0.8150861859321594\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=0.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=0.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 24\n",
            "\tTrainAcc=0.834482729434967\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.0\n",
            "\tBinAcc=0.3333333333333333\n",
            "\tSens=0.0\n",
            "\tSpec=0.5\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.0\n",
            "\tBinAcc=0.3333333333333333\n",
            "\tSens=0.0\n",
            "\tSpec=0.5\n",
            "\n",
            "Iterazione 25\n",
            "\tTrainAcc=0.8341946601867676\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=1.0\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=1.0\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 26\n",
            "\tTrainAcc=0.8146551847457886\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=1.0\n",
            "\tSens=1.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 27\n",
            "\tTrainAcc=0.8116379380226135\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.3333333333333333\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=0.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.3333333333333333\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=0.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Iterazione 28\n",
            "\tTrainAcc=0.8218588829040527\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.3333333333333333\n",
            "\tBinAcc=0.3333333333333333\n",
            "\tSens=1.0\n",
            "\tSpec=0.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.3333333333333333\n",
            "\tBinAcc=0.3333333333333333\n",
            "\tSens=1.0\n",
            "\tSpec=0.0\n",
            "\n",
            "Iterazione 29\n",
            "\tTrainAcc=0.8253012299537659\n",
            "\n",
            "Majority=False\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=0.0\n",
            "\tSpec=1.0\n",
            "\n",
            "Majority=Turne\n",
            "\tTernAcc=0.6666666666666666\n",
            "\tBinAcc=0.6666666666666666\n",
            "\tSens=0.0\n",
            "\tSpec=1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(acc_tern)\n",
        "print(acc)\n",
        "print(sens)\n",
        "print(spec)\n",
        "print(f'\\nAcc_tern: {np.mean(acc_tern)}')\n",
        "print(f'Acc: {np.mean(acc)}')\n",
        "print(f'Sens: {np.mean(sens)}')\n",
        "print(f'Spec: {np.mean(spec)}')\n",
        "\n",
        "print('\\n\\n')\n",
        "print(m_acc_tern)\n",
        "print(m_acc)\n",
        "print(m_sens)\n",
        "print(m_spec)\n",
        "print(f'\\nAcc_tern: {np.mean(m_acc_tern)}')\n",
        "print(f'Acc: {np.mean(m_acc)}')\n",
        "print(f'Sens: {np.mean(m_sens)}')\n",
        "print(f'Spec: {np.mean(m_spec)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faKRqmYTd5HQ",
        "outputId": "9ba1b9ad-d269-43c1-ab82-9bd188147199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666]\n",
            "[1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666]\n",
            "[1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]\n",
            "[1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0]\n",
            "\n",
            "Acc_tern: 0.6666666666666666\n",
            "Acc: 0.7555555555555554\n",
            "Sens: 0.6\n",
            "Spec: 0.8333333333333334\n",
            "\n",
            "\n",
            "\n",
            "[1.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666]\n",
            "[1.0, 0.3333333333333333, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666]\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]\n",
            "[1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0]\n",
            "\n",
            "Acc_tern: 0.6555555555555554\n",
            "Acc: 0.7555555555555554\n",
            "Sens: 0.6333333333333333\n",
            "Spec: 0.8166666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cMWaCkkkrYM7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}